[{"title":"使用github action 实现 maven 多模块编译 Spring Boot native image","url":"/2023/07/24/使用github-action-实现-maven-多模块编译-Spring-Boot-native-image/","content":"\n\n\n### pom 结构\n\n项目结构如下\n\n<img src=\"./image-20230724171111783.png\" >\n\n依赖关系\n\n> ​\tstart\n>\n> ​\t/     \\\t\n>\n>    user   video\n>\n> ​\t\\   \t/\n>\n> ​\t\tcommon\n\n\n\n要实现编译native image 所用到的pom build plugin如下\n\n\n\n主pom\n\n```xml\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.graalvm.buildtools</groupId>\n                <artifactId>native-maven-plugin</artifactId>\n            </plugin>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <configuration>\n                    <excludes>\n                        <exclude>\n                            <groupId>org.projectlombok</groupId>\n                            <artifactId>lombok</artifactId>\n                        </exclude>\n                    </excludes>\n                    <mainClass>xxxx 你的mainClass位置</mainClass>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n```\n\n\n\n入口pom\n\n```xml\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.graalvm.buildtools</groupId>\n                <artifactId>native-maven-plugin</artifactId>\n                <configuration>\n                    <skip>false</skip>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <configuration>\n                    <skip>false</skip>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n```\n\n\n\n依赖pom\n\n```xml\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <configuration>\n                    <skip>true</skip>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n```\n\n\n\n### github action 编译\n\n\n\n主要用到的是`graalvm/setup-graalvm@v1`\n\n#### Workflow file\n\nWorkflow file如下\n\n```yml\nname: GraalVM Native Image builds\non: [push, pull_request]\njobs:\n  build:\n    name: build on ${{ matrix.os }}\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [macos-latest, windows-latest, ubuntu-latest]\n    steps:\n      - uses: actions/checkout@v3\n\n      - uses: graalvm/setup-graalvm@v1\n        with:\n          java-version: '17.0.7'\n          distribution: 'graalvm'\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          native-image-job-reports: 'true'\n      - name: Build \n      \t# -DskipTests 可选\n        run: mvn -U clean install -DskipTests && mvn native:compile -Pnative -DskipTests \n      - name: Upload binary\n        uses: actions/upload-artifact@v2\n        with:\n          name: artifact-${{ matrix.os }}\n          path: xxx 这里填构建产物的位置\n```\n\n当action运行完后可以在artifact中获取到构建产物\n\n![image-20230724171921300](./image-20230724171921300.png)\n\n![image-20230724171933965](./image-20230724171933965.png)\n\n","tags":["github action","maven","native image"]},{"title":"jvm内存模型","url":"/2023/07/23/jvm内存模型/","content":"\n<div style=\"overflow: auto;\">\n    <img src=\"./image-20230723144425805.png\" style=\"float:left;width:49%\">\n    <img src=\"./image-20230723144655147.png\" style=\"float:right;width:49%\">\n</div>\n\n### 堆\n\n堆内存主要用于存储以下内容：\n\n1. 对象实例：堆内存中存储了Java应用程序创建的所有对象实例以及其实例变量。而每个对象实例的方法仅在方法区中存储一次，不会为每个对象实例单独存储。\n2. 数组：在堆中分配空间以存储数组元素。\n\n堆内存是垃圾回收器（Garbage Collector, GC）的主要工作区域。在此区域中，垃圾回收器负责自动回收不再使用的对象以释放内存资源。\n\n#### 堆内存的划分\n\n![image](./image.png)\n\n##### 年轻代（Young Generation）\n\n年轻代主要用于存储新创建的对象。它分为以下三个区域：\n\n1. Eden区：新创建的对象首先分配在这里。当Eden区满时，触发Minor GC（小型垃圾回收）。\n\n2. Survivor区 S0(Survivor Space 0)：存活的对象从Eden区移动至S0区。\n\n3. Survivor S1区(Survivor Space 1)：存活对象在S0和S1之间来回复制，每经过一个GC周期，它们将从一个Survivor区移动到另一个Survivor区。最终，经过若干次GC后，仍存活的对象将被移动到老年代。\n\n##### 老年代（Old Generation）\n\n长寿命周期的对象会被移动到这个区域。老年代比年轻代更大，且垃圾回收的频率较低。当老年代内存不足时，将触发Full GC（全面垃圾回收），清理年轻代和老年代中的对象。\n\n#### 堆内存中对象区域迁移过程\n\n1. 当新的对象创建时，首先在年轻代的Eden区分配内存。大多数对象在这个阶段就变得不可达，因此在接下来的Minor GC（小型垃圾回收）中会被回收。\n2. 当Eden区满时，Minor GC会触发。此时，垃圾回收器会清理Eden区并将存活对象移至Survivor区之一（例如Survivor S0区）。\n3. 在接下来的Minor GC中，垃圾回收器将再次清理Eden区。此次回收过程中，已在Survivor S0区的存活对象将与新存活的Eden区对象一并移动到Survivor S1区。与此同时，Survivor S0区的对象将被清理。\n4. 存活对象会在Survivor S0区和Survivor S1区之间来回迁移，直到达到一定年龄阈值（由JVM参数-XX:MaxTenuringThreshold设置）。一旦达到阈值，该对象将被移动到老年代（Old Generation）。\n5. 老年代用于存储长寿命周期的对象。当老年代的空间不足时，会触发Full GC（全面垃圾回收），此时包括年轻代和老年代在内的整个堆空间都会被回收。Full GC相比于Minor GC，效率较低，可能导致应用程序暂停(jvm调优往往是为了防止Full GC)\n\n### 方法区\n\n方法区会存储已被虚拟机加载的 类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。JDK 1.7中的永久代位于堆空间中，用于存储类元数据、字符串池等内容；而JDK 1.8中的元空间位于本地内存中，替换了永久代。\n\n#### 为什么将永久代替换为元空间\n\n永久代的大小是固定的，当类的元数据超过可用空间时，可能导致OutOfMemoryError。元空间位于本地内存（原生内存）中，可分配的空间更大，因此可降低因永久代限制导致内存溢出的风险。\n\n\n### 虚拟机栈\n\n虚拟机栈由栈帧构成，每次除native方法外的方法调用与返回对应了虚拟机栈的压入和弹出。\n\n栈帧的构成 \n\n![image-1](./image-1.png)\n\n#### 局部变量表\n\n用于存储该方法中定义的局部变量，包括基本数据类型、对象引用以及返回地址。局部变量表的大小在编译时确定，并在栈帧创建时分配内存。局部变量表中的索引从 0 开始，直到局部变量表的最大长度。\n\n#### 操作数栈\n\n用于在执行字节码指令时存储临时值、计算过程中的操作数和结果。操作数栈的最大深度由编译期确定，并在创建栈帧时分配内存。\n\n#### 动态链接\n\n栈帧中存储有指向运行时常量池（Runtime Constant Pool）中该方法所属类的引用。采用动态链接机制可在运行时解析并访问类中的方法和字段。\n\n#### 方法返回地址\n\n方法执行完毕后，需要将控制权返回给调用方法，方法返回地址负责记住调用方法中的下一条指令地址。这样，在执行完被调用方法后，便可从调用方法中的该地址恢复执行。\n\n### 本地方法栈\n\n类似虚拟机栈，用于native方法\n\n### 程序计数器\n\n指向下一条要执行的指令\n\n### 运行时常量池\n\n存储字面量和符号引用：运行时常量池主要用于存储编译期生成的各种字面量（如字符串、数字常量）和符号引用（如类名、字段名称、方法名称及描述符）。这些数据在类加载到JVM后，会存储于运行时常量池中。\n\n### 直接内存\n\n直接内存（Direct Memory）是指 Java 虚拟机（JVM）外的本地内存（Native Memory）。直接内存不受 JVM 堆内存管理和垃圾回收（GC）的控制。\n\n### jdk1.7和jdk1.8内存模型区别\n\n1. PermGen（永久代）和 Metaspace（元空间）：在JDK 1.7中，类元数据存储在名为PermGen（永久代）的内存区域中，这是一个受限的空间。当PermGen空间不足时，会引发OutOfMemoryError。而在JDK 1.8中，PermGen被Metaspace（元空间）所替代，它是存在于本地内存（而非堆内存）中的一块更大的区域。由于Metaspace不限制大小，因此它能有效地避免因PermGen导致的内存溢出错误。\n2. JDK 1.8引入了字符串去重机制，通过G1垃圾回收器来减少相同字符串在堆内存中的存储，从而节省内存空间。但在JDK 1.7中，并没有这个功能。\n","tags":["后端","jvm"]},{"title":"接口aes+rsa加密实践","url":"/2023/07/20/接口aes-rsa加密实践/","content":"\n\n\n对于需要加密的接口使用aes+rsa加密\n\n首先需要明确aes是一种对称加密算法，rsa是一种非对称加密算法。对于这两种加密算法的概念可以自行了解。\n\n**rsa加密的作用是为了加密aes密钥**\n\n这里提到的加密是对于请求数据和接口返回内容都进行加密\n\n### 基本流程\n\n1. 创建一个rsa密钥对\n2. 前端生成aes密钥\n3. 前端获取生成的rsa公钥\n4. 使用rsa公钥加密aes密钥\n5. 当前端请求加密接口时使用aes密钥加密请求数据，并且把rsa加密后的aes密钥放在请求头Sign的位置。\n6. 后端解密aes密钥，再使用解密后的aes密钥解密请求数据\n7. 后端使用aes密钥加密后返回数据\n8. 前端收到数据，使用aes密钥解密\n\n### 前端代码\n\n#### 封装aes加解密过程\n\n使用crypto-js进行aes加解密\n\njsencrypt进行rsa的加解密\n\n```ts\nimport CryptoJS from \"crypto-js\";\nimport JSEncrypt from \"jsencrypt\";\n\nconst iv = CryptoJS.enc.Utf8.parse(\"4382822409223508\");\n\nexport function Encrypt(data: string, k: string): string {\n  return CryptoJS.AES.encrypt(\n    CryptoJS.enc.Utf8.parse(data),\n    CryptoJS.enc.Utf8.parse(k),\n    {\n      iv: iv,\n      mode: CryptoJS.mode.CBC,\n      padding: CryptoJS.pad.Pkcs7,\n    }\n  ).toString()\n}\nexport function Decrypt(data: string, k: string): string {\n  return CryptoJS.enc.Utf8.stringify(CryptoJS.AES.decrypt(\n    data,\n    CryptoJS.enc.Utf8.parse(k),\n    {\n      iv: iv,\n      mode: CryptoJS.mode.CBC,\n      padding: CryptoJS.pad.Pkcs7,\n    }\n  ))\n}\n```\n\n这里面的iv为混淆向量，可以自己随意更改，但是要跟后端保持一致\n\n注意这里使用的aes模式是CBC/Pkcs7模式\n\n#### 获取rsa公钥，生成本地aes密钥\n\n```ts\nexport async function initEnc() {\n  if (useKeyStore().getKey().aesKey.length > 0) {\n    return true;\n  }\n  if (localStorage.getItem(\"e\")) {\n    let { aesKey, rsaPublicKey, encAesKey } = JSON.parse(localStorage.getItem(\"e\") as string)\n    useKeyStore().setKey(aesKey, rsaPublicKey, encAesKey)\n    return true;\n  }\n  let aesKey = generateKey()\n  let rsaPublicKey = // 这里替换成自己获取rsa公钥逻辑\n  let encrypt = new JSEncrypt()\n  encrypt.setPublicKey(rsaPublicKey)\n  let encAesKey = encrypt.encrypt(aesKey)\n  if (!encAesKey) {\n    throw new Error(\"加密失败\")\n  }\n  //存储到store\n  useKeyStore().setKey(aesKey, encrypt.getPublicKeyB64(), encAesKey)\n  // 持久化到localStorage\n  localStorage.setItem(\"e\", JSON.stringify(useKeyStore().getKey()))\n  return true;\n}\n\nexport function generateKey(): string {\n  return randomString(16);\n}\nfunction randomString(length: number): string {\n  const characters =\n    \"ABCDEFGHJKMNPQRSTWXYZabcdefhijkmnprstwxyz2345678\";\n  const charactersLength = characters.length;\n  let result = \"\";\n  for (let i = 0; i < length; i++) {\n    result += characters.charAt(Math.floor(Math.random() * charactersLength));\n  }\n  return result;\n}\n```\n\n在应用初始化的地方调用initEnc方法即可。\n\n这里用到了pinia做状态管理，存储aesKey，加密后的aesKey，rsa公钥\n\n定义如下\n\n```ts\nimport { defineStore } from \"pinia\";\n\nexport const useKeyStore = defineStore(\"keyStore\", {\n    state: () => ({\n        aesKey:\"\",\n        rsaPublicKey:\"\",\n        encAesKey:\"\",\n    }),\n    actions: {\n        setKey(aesKey: string,rsaPublicKey:string,encAesKey:string) {\n            this.aesKey = aesKey;\n            this.rsaPublicKey = rsaPublicKey;\n            this.encAesKey = encAesKey;\n        },\n        setKeyObj(p:any) {\n            this.aesKey = p[\"aesKey\"];\n            this.rsaPublicKey = p[\"rsaPublicKey\"];\n            this.encAesKey = p[\"encAesKey\"];\n        },\n        getKey() {\n            return this\n        }\n    }\n})\n```\n\n#### 对于axios进行封装,export一个request函数\n\n```ts\nconst request = <ResponseType = unknown>(\n    url: string,\n    options?: AxiosRequestConfig,\n    encReq: boolean = false,\n    encRes: boolean = false,\n): Promise<ResponseType> => {\n    const aesKey = useKeyStore().getKey().aesKey\n    const encAesKey = useKeyStore().getKey().encAesKey\n    if (encReq && options?.data) {\n        options.data = Encrypt(JSON.stringify(options.data), aesKey)\n    }\n    if (encReq || encRes) {\n        options = options == null ?\n            { headers: { 'sign': encAesKey } } :\n            { ...options, headers: { ...options.headers, 'sign': encAesKey } }\n    }\n    return new Promise((resolve, reject) => {\n        axiosInstance({\n            url,\n            ...options\n        })\n            .then(\n                (res: AxiosResponse) => {\n                    if (!res.headers.enc) {\n                        resolve(res.data.data)\n                        return\n                    }\n                    const aesKey = useKeyStore().getKey().aesKey\n                    res.data = JSON.parse(Decrypt(res.data, aesKey))\n                    resolve(res.data.data)\n                }\n            )\n            .catch(\n                (err) => reject(err)\n            )\n    })\n\n}\n```\n\n假设有一个加密接口，只需要这样调用即可\n\n```ts\nexport async function getXXXXDetail(id: number) {\n  return request<any>('/XXXX/detail', {\n    params:{\n      id\n    }\n  },true,true)\n}\n\n```\n\n### 后端代码\n\n思路主要是使用RequestBodyAdviceAdapter和ResponseBodyAdvice进行aop的解密和加密\n\n对于要加密的接口在方法上标注EncryptController注解\n\n```java\n@Inherited\n@Documented\n@Target({ElementType.FIELD, ElementType.TYPE, ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface EncryptController{\n\n    /**\n     * 传入参数是否加密\n     */\n    boolean requestEncrypt() default false;\n\n    /**\n     * 返回参数是否加密\n     */\n    boolean responseEncrypt() default false;\n\n}\n```\n\n加密接口定义\n\n```java\n\t@PutMapping\n    @EncryptController(requestEncrypt = true, responseEncrypt = true)\n    public Boolean userRegister(@RequestBody UserDto dto) {\n        return userService.userRegister(dto);\n    }\n```\n\n#### 请求解密\n\nhutool使用PKCS7时要添加另外的pom依赖\n\n```xml\n        <dependency>\n            <groupId>org.bouncycastle</groupId>\n            <artifactId>bcprov-jdk15to18</artifactId>\n            <version>1.68</version>\n        </dependency>\n```\n\n```java\n\n/**\n * @author:Franz Li\n * 请求参数解密\n */\n@ControllerAdvice\n@Slf4j\npublic class RequestEncryptAdvice extends RequestBodyAdviceAdapter {\n\n    @Resource\n    RSA rsa;\n\n    @Resource\n    RedisTemplate redisTemplate;\n\n    @Override\n    public boolean supports(MethodParameter methodParameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {\n        EncryptController methodAnnotation = methodParameter.getMethodAnnotation(EncryptController.class);\n        return methodAnnotation != null && methodAnnotation.requestEncrypt();\n    }\n\n    @Override\n    public HttpInputMessage beforeBodyRead(HttpInputMessage inputMessage,\n                                           MethodParameter parameter,\n                                           Type targetType,\n                                           Class<? extends HttpMessageConverter<?>> converterType) throws IOException {\n        if (inputMessage.getHeaders().get(EncConstant.AES_HEADER).size() > 0){\n            return decryptBody(inputMessage);\n        }\n        return inputMessage;\n    }\n\n\n    private HttpInputMessage decryptBody(HttpInputMessage inputMessage){\n        // 用rsa解密aesKey\n        String aesKey = Objects.requireNonNull(inputMessage.getHeaders().get(EncConstant.AES_HEADER)).get(0);\n        //redis优化\n        if (Boolean.TRUE.equals(redisTemplate.hasKey(EncConstant.AES_MAP_PREFIX + aesKey))) {\n            aesKey = (String) redisTemplate.opsForValue().get(EncConstant.AES_MAP_PREFIX + aesKey);\n        } else {\n            aesKey = rsa.decryptStr(aesKey, KeyType.PrivateKey);\n            redisTemplate.opsForValue().set(EncConstant.AES_MAP_PREFIX + aesKey, aesKey);\n        }\n        try{\n            byte[] body = new byte[inputMessage.getBody().available()];\n            inputMessage.getBody().read(body);\n            String bodyStr = new String(body);\n            AES aes = new AES(\"CBC\",\n                    \"PKCS7Padding\",\n                    aesKey.getBytes(StandardCharsets.UTF_8),\n                    \"4382822409223508\".getBytes(StandardCharsets.UTF_8));\n            log.debug(\"bodyStr:{}\", bodyStr);\n            bodyStr = aes.decryptStr(bodyStr,CharsetUtil.CHARSET_UTF_8);\n            byte[] decrypt = bodyStr.getBytes(StandardCharsets.UTF_8);\n            final ByteArrayInputStream bais = new ByteArrayInputStream(decrypt);\n            return new HttpInputMessage() {\n                @Override\n                public InputStream getBody() {\n                    return bais;\n                }\n                @Override\n                public HttpHeaders getHeaders() {\n                    return inputMessage.getHeaders();\n                }\n            };\n        }catch (Exception e){\n            log.error(\"解密失败 {}\",e);\n            throw new BusinessException(50000,\"加密参数异常\");\n        }\n    }\n\n}\n\n```\n\n#### 响应加密\n\n```java\n\n@Order(2)\n@RestControllerAdvice\npublic class ResponseEncryptAdvice implements ResponseBodyAdvice<Object> {\n\n    @Resource\n    RSA rsa;\n\n    @Override\n    public boolean supports(MethodParameter returnType, Class<? extends HttpMessageConverter<?>> converterType) {\n        EncryptController methodAnnotation = returnType.getMethodAnnotation(EncryptController.class);\n        return methodAnnotation != null && methodAnnotation.responseEncrypt();\n    }\n\n    @Override\n    public Object beforeBodyWrite(Object body,\n                                  MethodParameter returnType,\n                                  MediaType selectedContentType,\n                                  Class<? extends HttpMessageConverter<?>> selectedConverterType,\n                                  ServerHttpRequest request,\n                                  ServerHttpResponse response) {\n        response.getHeaders().set(\"enc\",\"true\");\n        String sign = request.getHeaders().get(EncConstant.AES_HEADER).get(0);\n        sign = rsa.decryptStr(sign, KeyType.PrivateKey);\n        AES aes = new AES(\"CBC\",\n                \"PKCS7Padding\",\n                sign.getBytes(StandardCharsets.UTF_8),\n                \"4382822409223508\".getBytes(StandardCharsets.UTF_8));\n        String content = JSONUtil.toJsonStr(body);\n        return aes.encryptBase64(content, StandardCharsets.UTF_8);\n    }\n}\n\n```\n\n有多个ResponseBodyAdvice时注意Order的顺序\n\n上文中注入的RSA对象可以自己按需求注入自己的对象。\n\n","tags":["后端","java","加密","前端"]},{"title":"分布式调度视频转码实践","url":"/2023/07/01/分布式调度视频转码实践/","content":"\n业务场景: 用户上传视频，通过转码服务器转换成不同码率之后再生成m3u8文件，最后通过hls技术在平台播放。\n\n技术分析:\n\n1. 视频以及转码后的视频文件存储位置。考虑到拓展性，选择minio作为存储服务。\n2. 视频转码 ffmpeg\n3. 分布式任务调度 xxl-job,通过xxl-job调度转码服务器拉取minio内容并且转码后推送到minio\n\n大体流程如下\n\n![2023-06-30_11-29](img1.png)\n\n## xxl-job搭建\n\n<a href=\"https://www.xuxueli.com/xxl-job/#%E4%BA%8C%E3%80%81%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8\">参考xxl-job官方文档的快速入门部分</a>\n\n因为要通过调度中心触发任务，官方给的RESTful API的示例只能直接通过执行器ip的方式触发。通过调试发现调度中心触发任务是通过 http://调度中心地址/jobInfo/trigger的方式触发的。\n找到对应的源码处为`com.xxl.job.admin.controller.JobInfoController#triggerJob`\n我们无法直接调用这个接口，因为这个接口存在鉴权。\n\n```java\n@RequestMapping(\"/trigger\")\n\t@ResponseBody\n\tpublic ReturnT<String> triggerJob(int id, String executorParam, String addressList) {\n\t\t// force cover job param\n\t\tif (executorParam == null) {\n\t\t\texecutorParam = \"\";\n\t\t}\n\n\t\tJobTriggerPoolHelper.trigger(id, TriggerTypeEnum.MANUAL, -1, null, executorParam, addressList);\n\t\treturn ReturnT.SUCCESS;\n\t}\n```\n\n通过分析源码发现xxl-job的鉴权主要是通过`com.xxl.job.admin.controller.annotation.PermissionLimit`注解和`com.xxl.job.admin.controller.interceptor.PermissionInterceptor`拦截器\n通过在对于的接口处加上`@PermissionLimit(limit = false)`即可避免接口的鉴权，但是这并不是安全的做法，推荐重新自定义这个接口的鉴权逻辑。\n\n通过以上修改我们可以通过http://调度中心地址/jobInfo/trigger这个api触发任务。\n\n## 执行器编写\n\n执行器的目的是为了将mino中的视频转码为不同码率，并且转换为m3u8,所以执行器需要部署在转码服务器上。\n\n通过xxl-job的BEAN模式（类形式）编写执行器\n\n通过xxl-job的jobParam传递转码参数。\n\n注：执行器代码结构并未优化请自行优化\n\n```java\nimport cn.hutool.core.io.FileUtil;\nimport cn.hutool.core.lang.UUID;\nimport cn.hutool.json.JSONUtil;\nimport com.xxl.job.core.context.XxlJobHelper;\nimport com.xxl.job.core.handler.IJobHandler;\nimport io.minio.DownloadObjectArgs;\nimport io.minio.MinioClient;\n\nimport java.io.*;\n\npublic class FfmpgeExecutor extends IJobHandler {\n\n    private MinioClient minioClient;\n\n    private static final String tmpPath = \"/home/franz/tmp/cover-executor/\";\n\n    private static final String logFormat = \"=====================  %s =====================\";\n\n    private static JobParam jobParam;\n\n    @Override\n    public void init() throws Exception {\n        super.init();\n    }\n\n    @Override\n    public void execute() throws IOException, InterruptedException {\n        XxlJobHelper.log(logFormat.formatted(\"start cover task\"));\n\n        String param = XxlJobHelper.getJobParam();\n\n        jobParam = JSONUtil.toBean(param, JobParam.class);\n        XxlJobHelper.log(param);\n\n        String fileName = jobParam.getFileName();\n        String filePath = tmpPath + fileName;\n\n        if (FileUtil.exist(filePath)) {\n            FileUtil.del(filePath);\n        }\n\n        minioClient = MinioClient.builder()\n                .endpoint(jobParam.getEndpoint())\n                .credentials(jobParam.getAccessKey(), jobParam.getSecretKey())\n                .build();\n\n        XxlJobHelper.log(logFormat.formatted(\"try pull resource from oss\"));\n        try {\n            DownloadObjectArgs downloadObjectArgs = DownloadObjectArgs\n                    .builder()\n                    .bucket(jobParam.getBucketName())\n                    .object(jobParam.getFileName())\n                    .filename(filePath)\n                    .build();\n            minioClient.downloadObject(downloadObjectArgs);\n        } catch (Exception e) {\n            XxlJobHelper.log(logFormat.formatted(\"pull resource from oss failed\"));\n            throw new RuntimeException(e);\n        }\n\n        // 执行ffmpeg命令\n        XxlJobHelper.log(logFormat.formatted(\"try execute ffmpeg\"));\n\n        String uuid = UUID.fastUUID().toString();\n\n        ProcessBuilder builder = new ProcessBuilder(\"/bin/sh\", \"-c\",\n                \"\"\"\n                        ffmpeg -threads 0 -vsync 1 -i %s \\\\\n                            -preset ultrafast \\\\\n                            -lavfi '[0] scale=1280:720[hd],[0] scale=1920:1080[fhd]' \\\\\n                            -vsync 1 \\\\\n                            -c:v libx264 -c:a aac -b:v:0 2800k -b:a:0 128k -b:v:1 5000k -b:a:1 192k \\\\\n                            -map '[hd]' -map 0:a -map '[fhd]' -map 0:a \\\\\n                            -var_stream_map 'v:0,agroup:hd,name:video_hd a:0,agroup:hd,name:audio_hd v:1,agroup:fhd,name:video_fhd a:1,agroup:fhd,name:audio_fhd' \\\\\n                            -f hls -master_pl_name %s.m3u8 \\\\\n                            -ar 44100 -ac 2 \\\n                            -hls_wrap 0 \\\\\n                            -g 120 -keyint_min 120 -sc_threshold 0 -muxpreload 0 -muxdelay 0 \\\\\n                            -hls_time 20 -hls_flags single_file -hls_playlist_type vod -hls_list_size 0 \\\\\n                            -hls_segment_type fmp4 -hls_segment_filename '%s%%v.mp4' %s%%v.m3u8\n                        \"\"\".formatted(filePath, uuid, tmpPath, tmpPath));\n\n        // 将标准输出和错误输出合并\n        builder.redirectErrorStream(true);\n\n        // 启动进程\n        Process process = builder.start();\n\n        // 获取输入流\n        InputStream inputStream = process.getInputStream();\n        BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream));\n\n        String line;\n\n        // 逐行读取输出\n        while ((line = reader.readLine()) != null) {\n            XxlJobHelper.log(line);\n            System.out.println(line);\n        }\n\n        // 等待进程执行完毕\n        int exitCode = process.waitFor();\n        XxlJobHelper.log(logFormat.formatted(\"脚本执行完毕，退出码：\" + exitCode));\n\n\n        // 删除原始视频文件\n        FileUtil.del(filePath);\n\n        // 获取临时文件夹所有文件\n        File[] files = FileUtil.ls(tmpPath);\n\n        // 上传文件到oss\n        for (File file : files) {\n            XxlJobHelper.log(logFormat.formatted(\"try upload \" + file.getName() + \" to oss\"));\n            try {\n                minioClient.uploadObject(io.minio.UploadObjectArgs.builder()\n                        .bucket(jobParam.getBucketName())\n                        .object(file.getName())\n                        .filename(file.getAbsolutePath())\n                        .build());\n            } catch (Exception e) {\n                XxlJobHelper.log(logFormat.formatted(\"upload file to oss failed\"));\n                throw new RuntimeException(e);\n            }\n        }\n\n        // 删除oss中原始视频文件\n        XxlJobHelper.log(logFormat.formatted(\"try delete \" + fileName + \" from oss\"));\n        try {\n            minioClient.removeObject(io.minio.RemoveObjectArgs.builder()\n                    .bucket(jobParam.getBucketName())\n                    .object(fileName)\n                    .build());\n        } catch (Exception e) {\n            XxlJobHelper.log(logFormat.formatted(\"delete file from oss failed\"));\n            throw new RuntimeException(e);\n        }\n\n    }\n\n    static class JobParam {\n\n        private String endpoint;\n\n        private String accessKey;\n\n        private String secretKey;\n\n        private String bucketName;\n\n        private String fileName;\n\t\t\n        ...getter and setter\n    }\n}\n```\n\n上面代码中使用到的ffmpeg指令并为使用gpu加速，并且为了转码速度添加了`-preset ultrafast`参数，请根据实际环境更改ffmpeg的指令，或者通过更加推荐的jave2的方式在java中使用ffmpeg\n\n上面用的是直接通过minio的java sdk操作的文件，但是ffmpeg好像可以直接通过minio的s3协议直接推送和拉取minio中的资源，反正我没成功。可以自行尝试。\n\n## 服务后端\n\n服务后端主要接口是生成minio的签名上传url和触发任务\n\n### 签名上传\n\n```java\n    @GetMapping(\"tempurl/{id}/{name}\")\n    public ResponseEntity<ResponseResult> getTempUrl(@PathVariable String name, @PathVariable String id) {\n        if (StrUtil.isBlankIfStr(name)) {\n            name = UUID.fastUUID().toString();\n        }\n\n        OssSource ossSource = service.getById(id);\n        Object client = OssFactory.createOssClient(ossSource);\n\n        String url = null;\n\n        if (ossSource.getType().equals(\"minio\")) {\n            MinioClient minioClient = (MinioClient) client;\n            try {\n                url = minioClient.getPresignedObjectUrl(GetPresignedObjectUrlArgs\n                        .builder()\n                        .bucket(ossSource.getBucketName())\n                        .object(name)\n                        .method(Method.PUT)\n                        .expiry(60 * 60 * 24)\n                        .build()\n                );\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        Map<String, String> m = Map.of(\"url\", url);\n        return ResponseEntity.ok(ResponseResult.success(m));\n    }\n\n```\n\n出于方便，代码都写在controller里了\n\n### 任务触发\n\n```java\npublic class XxlJobutil {\n\n    @Value(\"xxl-job.admin.addresses\")\n    private static String adminAddresses;\n\n    @Value(\"xxl-job.executor.jobId\")\n    private static Integer JobId;\n\n    public static String triggerJob(String fileName){\n        adminAddresses = addSplit4url(adminAddresses);\n        String triggerUrl = adminAddresses + \"jobinfo/trigger\";\n        Map<String, Object> paramMap = new HashMap<>();\n        paramMap.put(\"id\", JobId);\n\n        JobParam jobParam = new JobParam();\n        jobParam.setEndpoint(adminAddresses);\n        jobParam.setAccessKey(ak);\n        jobParam.setSecretKey(ak);\n        jobParam.setBucketName(bk);\n        jobParam.setFileName(fileName);\n\n        paramMap.put(\"executorParam\", JSONUtil.toJsonStr(jobParam));\n        paramMap.put(\"addressList\", \"\");\n        return HttpUtil.post(triggerUrl, paramMap, 10000);\n    }\n\n    private static String addSplit4url(String url) {\n        if (url.endsWith(\"/\")) {\n            return url;\n        } else {\n            return url + \"/\";\n        }\n    }\n\n}\n\n\n```\n\n最终效果\n![2023-07-01_16-08](img2.png)\n\n\n\n![2023-07-01_16-09](img3.png)\n","tags":["后端","ffmpeg","xxl-job","minio"]},{"title":"sso模式之URL重定向传播会话","url":"/2023/06/05/sso模式之URL重定向传播会话/","content":"\n## SSO是什么\n\nSSO既SingleSignOn，用户在身份认证服务器上登录一次后，即可无需登录访问其他单点登录系统中的信息。\n\n本文中认证服务器为 auth.fzzzzz.tech\n\n客户端1 client.stp.com\n\n客户端2 client2.stp.com\n\n部署在不同的域名之下，但是后端可以连接同一个Redis\n\n最终效果如图\n\n![screenshots](screenshots-1685966891054-2.gif)\n\n当在客户端2通过认证服务器认证后，客户端2获得登录状态，客户端1登录时用户可以无感登录。\n\n## 原理\n\n1. 用户跳转到子系统登录接口\n\n   http://auth.fzzzzz.tech:5500/sso2/auth/，并携带back参数记录初始页面URL。\n\n   登录接口将获得新的cookie\n\n\n   - 形如：`http://{sso-client}/sso/login?back=xxx`\n\n3. 子系统检测到此用户尚未登录，再次将其重定向至SSO认证中心，并携带redirect参数\n\n   记录子系统的登录页URL。\n\n   - 形如：`http://{sso-server}/sso/auth?redirect=xxx?back=xxx`\n\n4. 用户进入了 SSO认证中心 的登录页面，开始登录。\n\n5. 用户 输入账号密码 并 登录成功，SSO认证中心再次将用户重定向至子系统的登录接口   /sso/login，并携带ticket码参数。\n\n   - 形如：`http://{sso-client}/sso/login?ticket=xxxxxxxxx`\n\n6. 子系统根据 `ticket码` 从 `SSO-Redis` 中获取账号id，并在子系统登录此账号会话。\n7. 当其他系统进入统一登录接口时，因为存在cookie，直接如同第5步返回ticket\n\n## 代码实现\n\n### 后端认证代码实现\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/redis/go-redis/v9\"\n\tuuid \"github.com/satori/go.uuid\"\n\t\"log\"\n\t\"net/http\"\n\t\"time\"\n)\n\nvar rdb = redis.NewClient(&redis.Options{\n\tAddr:     \"xxxxxxxxxx\",\n\tPassword: \"xxxxxxxxxx\",\n\tDB:       0,             // 默认DB 0\n})\nvar ctx = context.Background()\n\n// 跨域中间件\nfunc CrosMiddleware(handler http.HandlerFunc) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\tw.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\n\t\tw.Header().Set(\"Access-Control-Allow-Methods\", \"POST, GET, PUT, DELETE, OPTIONS\")\n\t\t//放行所有OPTIONS方法\n\t\tif r.Method == \"OPTIONS\" {\n\t\t\tw.WriteHeader(200)\n\t\t\treturn\n\t\t}\n\t\thandler.ServeHTTP(w, r)\n\t})\n}\n\n//通过用户名和密码 或者 cookie返回ticket\nfunc auth(w http.ResponseWriter, r *http.Request) {\n\t// 模拟登录\n\t// 如果cookie不存在\n\tif username := r.FormValue(\"username\"); username == \"admin\" &&\n\t\tr.FormValue(\"password\") == \"admin\"{\n\t\ttk := uuid.NewV4().String()\n\t\tcookie := &http.Cookie{\n\t\t\tName:  \"token\",\n\t\t\tValue: tk,\n\t\t}\n\t\tif err := rdb.Set(ctx, \"user.login.session.\"+username, tk, 0).Err();err != nil {\n\t\t\tlog.Fatal(\"redis error\")\n\t\t}\n\t\thttp.SetCookie(w, cookie)\n\t\tticket := uuid.NewV4().String()\n\t\tif err1 := rdb.Set(ctx, \"user.login.ticket.\"+ticket, username, 100*time.Second).Err();err1 != nil {\n\t\t\tlog.Fatal(\"redis error\")\n\t\t}\n\t\tw.Write([]byte(fmt.Sprintf(\"{\\\"code\\\":200,\\\"msg\\\":\\\"success\\\",\\\"ticket\\\":\\\"%s\\\"}\", ticket)))\n\t} else if cookie, cookieErr := r.Cookie(\"token\"); cookieErr == nil {\n\t\t// 如果 cookie 存在\n\t\tusername := rdb.Get(ctx, \"user.login.session.\"+cookie.Value).Val()\n\t\tticket := uuid.NewV4().String()\n\t\terr1 := rdb.Set(ctx, \"user.login.ticket.\"+ticket, username, 100*time.Second).Err()\n\t\tif err1 != nil {\n\t\t\tlog.Fatal(\"redis error\")\n\t\t}\n\t\tw.Write([]byte(fmt.Sprintf(\"{\\\"code\\\":200,\\\"msg\\\":\\\"success\\\",\\\"ticket\\\":\\\"%s\\\"}\", ticket)))\n\t} else {\n\t\tw.Write([]byte(\"{\\\"code\\\":500,\\\"msg\\\":\\\"fail\\\",\\\"ticket\\\":\\\"null\\\"}\"))\n\t}\n}\n\n// 通过ticket返回token\nfunc ticketAuth(w http.ResponseWriter, r *http.Request) {\n\t// 根据用户名返回ticket\n\tticket := r.FormValue(\"ticket\")\n\ttk := uuid.NewV4().String()\n\tcookie := &http.Cookie{\n\t\tName:  \"token\",\n\t\tValue: tk,\n\t}\n\thttp.SetCookie(w, cookie)\n\tif err := rdb.Set(ctx, \"user.login.session.\"+rdb.Get(ctx, \"user.login.ticket.\"+ticket).Val(), tk, 0).Err();err != nil {\n\t\tlog.Fatal(\"redis error\")\n\t}\n}\n\nfunc main() {\n\thttp.Handle(\"/auth\", CrosMiddleware(auth))\n\thttp.Handle(\"/sso\", CrosMiddleware(ticketAuth))\n\terr := http.ListenAndServe(\":80\", nil) // 设置监听的端口\n\tif err != nil {\n\t\tlog.Fatal(\"ListenAndServe: \", err)\n\t}\n}\n\n```\n\n### 前端认证代码\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>sso-auth</title>\n</head>\n\n<body>\n    \n</body>\n<script>\n    render()\n\n    document.querySelector(\"form\").addEventListener('click', function (event) {\n        event.preventDefault();\n    });\n\n    document.querySelector(\"input[type='submit']\").addEventListener('click', function (event) {\n        event.preventDefault();\n        login();\n    });\n\n    // 如果存在cookie 自动跳转回源页面\n    if (getCookie(\"token\")) {\n        // console.log(getCookie(\"token\"));\n        autoLoginIfLogin()\n    }\n\n    // 登录方法\n    async function login() {\n        let username = document.querySelector(\"input[name='username']\").value;\n        let password = document.querySelector(\"input[name='password']\").value;\n        let res = await fetch(`http://auth.fzzzzz.tech/auth?username=${username}&password=${password}`, {\n            method: \"GET\",\n            credentials: \"include\"\n        })\n        let body = await res.json()\n        document.querySelector(\".msg\").innerHTML = body['msg']\n        //重定向\n        redi(body['ticket'])\n    }\n\n    async function autoLoginIfLogin() {\n        let res = await fetch(`http://auth.fzzzzz.tech/auth`, {\n            method: \"GET\",\n            credentials: \"include\"\n        })\n        let body = await res.json()\n        document.querySelector(\".msg\").innerHTML = body['msg']\n        redi(body['ticket'])\n    }\n\n    function render(){\n        document.querySelector('body').innerHTML = `登录\n    <form>\n        <input type=\"text\" name=\"username\" placeholder=\"用户名\"><br />\n        <input type=\"password\" name=\"password\" placeholder=\"密码\"><br />\n        <input type=\"submit\" value=\"登录\">\n        <button onclick='clearCookie()'>清空cookie</button>\n        <div class=\"msg\"></div>\n    </form>`\n    }\n   \n    function redi(ticket) {\n        // 重定向回back\n        let back = getQueryString(\"back\")\n        console.log(back);\n        back.includes(\"?\") ? window.location.href = `${back}&ticket=${ticket}` : window.location.href = `${back}?ticket=${ticket}`\n        \n    }\n\n    function getQueryString(name) {\n        var reg = new RegExp('(^|&)' + name + '=([^&]*)(&|$)', 'i');\n        var r = window.location.search.substr(1).match(reg);\n        if (r != null) {\n            return unescape(r[2]);\n        }\n        return null;\n    }\n    \n    // 清除所有cookie\n    function clearCookie() {\n        var keys = document.cookie.match(/[^ =;]+(?=\\=)/g);\n        if (keys) {\n            for (var i = keys.length; i--;) {\n                document.cookie = keys[i] + '=0;path=/;expires=' + new Date(0).toUTCString();\n                document.cookie = keys[i] + '=0;path=/;domain=' + document.domain + ';expires=' + new Date(0).toUTCString();\n                document.cookie = keys[i] + '=0;path=/;domain=kevis.com;expires=' + new Date(0).toUTCString();\n            }\n        }\n        console.log('已清除');\n    }\n\n    // 获取cookie方法\n    function getCookie(name) {\n        var cookieArr = document.cookie.split(\";\");\n        for (var i = 0; i < cookieArr.length; i++) {\n            var cookiePair = cookieArr[i].split(\"=\");\n            if (name == cookiePair[0].trim()) {\n                return decodeURIComponent(cookiePair[1]);\n            }\n        }\n        return null;\n    }\n</script>\n\n</html>\n```\n\n### 测试客户端代码\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>sso-client</title>\n</head>\n\n<body>\n\n</body>\n<script>\n\n    render()\n\n    if (getQueryString(\"ticket\")) {\n        loginByTicket(getQueryString(\"ticket\")).then(() => {\n            render()\n        })\n    }\n\n    async function loginByTicket(ticket) {\n        let url = window.location.origin\n        // 如果有端口移除端口\n        if (url.split(\":\").length > 2) {\n            url = url.split(\":\")[0] + \":\" + url.split(\":\")[1]\n        }\n        let res = await fetch(`${url}/sso?ticket=${ticket}`, {\n            method: \"GET\",\n            credentials: \"include\"\n        })\n        // 移除ticket\n        window.history.replaceState({}, null, window.location.href.split(\"?\")[0])\n    }\n\n    function clearCookie() {\n        var keys = document.cookie.match(/[^ =;]+(?=\\=)/g);\n        if (keys) {\n            for (var i = keys.length; i--;) {\n                document.cookie = keys[i] + '=0;path=/;expires=' + new Date(0).toUTCString();\n                document.cookie = keys[i] + '=0;path=/;domain=' + document.domain + ';expires=' + new Date(0).toUTCString();\n                document.cookie = keys[i] + '=0;path=/;domain=kevis.com;expires=' + new Date(0).toUTCString();\n            }\n        }\n        console.log('已清除');\n    }\n\n    function render() {\n        document.querySelector(\"body\").innerHTML =\n            getCookie(\"token\") ?\n                `已登录 cookie = ${getCookie(\"token\")}` :\n                `未登录 <a href='http://auth.fzzzzz.tech:5500/sso2/auth/?back=${window.location.href}'>去认证中心登录</a>`;\n        document.querySelector(\"body\").innerHTML += \"<br /><button onclick='clearCookie()'>清空cookie</button>\"\n    }\n\n    function getCookie(name) {\n        var cookieArr = document.cookie.split(\";\");\n        for (var i = 0; i < cookieArr.length; i++) {\n            var cookiePair = cookieArr[i].split(\"=\");\n            if (name == cookiePair[0].trim()) {\n                return decodeURIComponent(cookiePair[1]);\n            }\n        }\n        return null;\n    }\n\n    function getQueryString(name) {\n        var reg = new RegExp('(^|&)' + name + '=([^&]*)(&|$)', 'i');\n        var r = window.location.search.substr(1).match(reg);\n        if (r != null) {\n            return unescape(r[2]);\n        }\n        return null;\n    }\n\n</script>\n</html>\n```\n\n","tags":["后端","go","sso"]},{"title":"sse 的原理以及java下的简单实现","url":"/2023/05/19/sse 的原理以及java下的简单实现/","content":"\n前段时间看到gpt返回时的部分输出的效果，觉得很有意思，所以研究了下是怎么实现的。\n\n主要是通过sse（Server-Sent Events）技术实现的这种效果\n\n## 简介\n\nSSE（Server-Sent Events）和WebSocket都是用于实现服务器和客户端之间的实时通信的技术，但它们有一些区别。\n\nSSE是一种单向通信协议，它允许服务器向客户端发送事件流。客户端通过一个持久化的HTTP连接接收事件流，这个连接可以保持打开状态，直到客户端关闭连接或服务器关闭连接。\n\nWebSocket是一种双向通信协议，它允许服务器和客户端之间进行实时双向通信。WebSocket通过一个持久化的TCP连接实现双向通信，客户端和服务器可以随时发送消息。\n\n## sse\n\n### 1.如何保持长连接\n\n在http 1.1下Keep-Alive模式默认开启，服务端会通过tcp协议发送一个不带数据的ack请求，确保客户端的在线。\n\n### 2.如何判断数据完整性\n\n当客户端接收到数据后会通过判断`Content-Length`或者`Transfer-Encoding`响应头判断哪一部分是完整数据。\n\n### 3.客户端如何判断是sse\n\n通过客户端设置响应头`Content-type`为`text/event-stream`。\n\n![image-20230519105824786](img1.png)\n\n### java简单代码实现\n\n```java\n@WebServlet(urlPatterns = \"/streaming\",asyncSupported = true)\npublic static class StreamingServlet extends HttpServlet {\n\n    private static final long serialVersionUID = 1L;\n    private ExecutorService executorService = Executors.newCachedThreadPool();\n\n    @Override\n    protected void doGet(HttpServletRequest request, HttpServletResponse response)\n        throws ServletException, IOException {\n        // 设置响应内容类型为SSE\n        response.setContentType(\"text/event-stream\");\n        response.setCharacterEncoding(\"UTF-8\");\n        // 开启异步上下文\n        final AsyncContext asyncContext = request.startAsync();\n        // 使用线程池执行任务\n        executorService.execute(() -> {\n            try {\n                PrintWriter writer = response.getWriter();\n                for (int i = 0; i < 10; i++) {\n                    // 发送数据\n                    writer.write(\"data: \" + i + \"\\n\\n\");\n                    writer.flush();\n\n                    // 模拟数据产生的延迟\n                    Thread.sleep(1000);\n                }\n            } catch (IOException | InterruptedException e) {\n                e.printStackTrace();\n            } finally {\n                asyncContext.complete();\n            }\n        });\n    }\n    @Override\n    public void destroy() {\n        // 关闭线程池\n        executorService.shutdown();\n    }\n}\n```\n\n效果\n\n![image-20230519110903114](img2.png)\n\n#### AsyncContext\n\n看到别人实现sse时都使用的AsyncContext，但是并不知道有啥用,查询资料后得知\n\n使用`final AsyncContext asyncContext = request.startAsync();`可以实现Servlet 线程将请求转交给一个异步线程来执行业务处理，线程本身返回至容器，等待异步线程任务结束后可以直接生成响应数据。\n\n","tags":["后端","java","sse"]},{"title":"nginx 中使用中文路径使用 try_files 的一些坑","url":"/2023/04/12/nginx-中使用中文路径使用-try-files-的一些坑/","content":"\nnginx 配置如下\n\n```properties\nlocation ~ /download/(?<filename>.*) {\n            set $bid \"\";\n            set $filename $1;\n            access_by_lua_file lua/auth.lua;\n            root /toss/;\n            try_files /$bid/$filename /$filename =404;\n            lua_code_cache off;\n\t        charset utf-8;\t        \n}\n```\n\n当通过 http://example.com/download/测试.jpg 时出现404 no found问题\n\n原因是filename变量是通过urlencode后的值，nginx在磁盘中找不到该文件\n\n\n\n解决方法: 通过access_by_lua_file解码并修改更改filename的值\n\n核心代码如下：\n\n```lua\nlocal function urlDecode(s)\n    s = string.gsub(s, '%%(%x%x)', function(h) return string.char(tonumber(h, 16)) end)\n    return s\nend\nngx.var.filename = urlDecode(ngx.var.filename)\n```\n\n\n\n如果解码之后还是出现404 no found可以使用`locale`检查一下服务器编码确定是utf-8编码，即LANG=en_US.utf8 并且在location块配置charset utf-8;\n\n","tags":["nginx"]},{"title":"Openresty 实现 WebDAV 功能 ，并且实现在 WebDAV 下多用户认证以及访问目录控制 - 2","url":"/2023/04/06/Openresty-实现-WebDAV-功能-，并且实现在-WebDAV-下多用户认证以及访问目录控制-2/","content":"\n\n\n[关于openresty-dav的编译以及简单的webdav部署请看上文](https://blog.frzli.top/2023/03/25/Openresty-%E5%AE%9E%E7%8E%B0-WebDAV-%E5%8A%9F%E8%83%BD-%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%AE%9E%E7%8E%B0%E5%9C%A8-WebDAV-%E4%B8%8B%E5%A4%9A%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%E4%BB%A5%E5%8F%8A%E8%AE%BF%E9%97%AE%E7%9B%AE%E5%BD%95%E6%8E%A7%E5%88%B6/)\n\n在上文中我们编译了带WebDAV功能的Openresty，并且实现了简单的WebDAV功能\n\n## Openresty配置文件\n\n```\n        location ~ /dav/(?<bucket_id>\\d+)/(?<sub_path>.*) {\n            set $user_path \"\";\n            set $bucket_id $1;\n            # 临时文件夹\n            client_body_temp_path /toss/tmp;\n            # webdav 支持的方式\n            dav_methods  PUT DELETE MKCOL COPY MOVE;\n            # webdav 插件支持的请求方式\n            dav_ext_methods PROPFIND OPTIONS LOCK UNLOCK;\n\n            create_full_put_path on;\n            # 访问权限\n            dav_access      user:rw group:rw  all:r;\n\n            #禁止创建文件夹\n            if ($request_method = MKCOL) {\n                return 405;\n            }\n            # 网页自动索引\n            autoindex on;\n            # 基于 http basic 的认证\n            auth_basic \"Authorized Users Only\";\n            # 权限控制和 user_path 控制\n            access_by_lua_file lua/webdav_auth.lua;\n            # 设置目录\n            alias $user_path/$sub_path;\n        }\n```\n\n\n\n可以通过access_by_lua_file文件动态控制webdav访问的目录以及用户认证。\n\n在lua file中设置$user_path以及$sub_path变量\n\n通过http basic进行用户的认证\n\n\n\n## lua脚本编写\n\n```lua\nlocal mysql = require(\"resty.mysql\")\nlocal resty_sha1 = require(\"resty.sha1\")\nlocal str = require(\"resty.string\")\n\nlocal headers = ngx.req.get_headers()\nlocal authorization = headers[\"Authorization\"]\n\nlocal salt = \"qefd1y098ehudi\"\n\n\nlocal db, err = mysql:new()\nif not db then\n    ngx.log(ngx.ERR, \"failed to instantiate mysql: \", err)\n    return\nend\ndb:set_timeout(1000)\nlocal ok, err, errno, sqlstate = db:connect {\n    host = \"db\",\n    port = 3306,\n    database = \"dbname\",\n    user = \"root\",\n    password = \"pwd\"\n}\nif not ok then\n    ngx.log(ngx.ERR, \"failed to connect: \", err, \": \", errno, \" \", sqlstate)\n    return\nend\nlocal function close_db(db)\n    if not db then\n        return\n    end\n    db:close()\nend\n\nlocal function check(username, password)\n    local sha1 = resty_sha1:new()\n    sha1:update(password)\n    sha1:update(salt)\n    local digest = sha1:final()\n    local pwd = tostring(str.to_hex(digest))\n    local quoted = ngx.quote_sql_str(tostring(username))\n    local sql = \"SELECT count(*) sum FROM `tb_sysuser` where `username` =  \" ..quoted.. \"  and `password` =  '\" ..pwd .. \"'\"\n    ngx.log(ngx.ALERT,\"sql = \" .. sql)\n    res, err, errno, sqlstate = db:query(sql)\n\n    if not res then\n        ngx.log(ngx.ALERT,\"database Error \\n\" .. err)\n        close_db(db)\n        return\n    end\n\n    for i, row in ipairs(res) do\n        for name, value in pairs(row) do\n            if name == \"sum\" then\n                ngx.log(ngx.ALERT, \"value = \" .. value)\n                return value == \"1\"\n            end\n        end\n    end\n\n    return false\n\nend\n\nlocal function checkPriviledge(username)\n    local quoted = ngx.quote_sql_str(tostring(username))\n    \n    local sql = \"select privilege from tb_bucket_privilege where bid = \"..ngx.var.bucket_id..\" and uid = (SELECT id from tb_sysuser where username = \"..quoted..\" )\"\n\n    ngx.log(ngx.ALERT,\"sql = \" .. sql)\n\n    res, err, errno, sqlstate = db:query(sql)\n\n    if not res then\n        ngx.log(ngx.ALERT,\"database Error \\n\" .. err)\n        close_db(db)\n        return\n    end\n\n    for i, row in ipairs(res) do\n        for name, value in pairs(row) do\n            if name == \"privilege\" then\n                close_db(db)\n                ngx.log(ngx.ALERT, \"value = \" .. value)\n                return value == \"rw\"\n            end\n        end\n    end\n\n    return false\nend\n\nlocal function fail()\n    ngx.header[\"WWW-Authenticate\"] = 'Basic realm=\"Restricted Area\"'\n    ngx.exit(ngx.HTTP_UNAUTHORIZED)\nend\n\n\nif authorization then\n    local encoded = authorization:sub(7)\n    local decoded = ngx.decode_base64(encoded)\n    local username, password = decoded:match(\"([^:]*):(.*)\")\n    ngx.log(ngx.ALERT, username .. \":\" .. password)\n    if check(username, password) then\n        ngx.req.set_header(\"X-User\", username)\n        local readlPath = \"/toss/\" .. ngx.var.bucket_id\n        ngx.log(ngx.ALERT,readlPath)\n        if checkPriviledge(username) then\n            ngx.var.user_path = readlPath\n        else\n            fail()\n        end\n    else\n        fail()\n    end\nelse\n    fail()\nend\n```\n\n通过上述lua脚本控制访问权限和访问目录\n\n注意上面lua脚本默认的访问根目录是 /toss/\n\n通过访问mysql数据库校验权限\n\n","tags":["后端","webdav","Openresty","lua"]},{"title":"docker-compose + shell 一键化项目部署的一次尝试","url":"/2023/04/05/docker-compose-shell-一键化项目部署的一次尝试/","content":"\n## 业务场景\n\n某项目存在以下架构\n\n![image-20230405171010054](image-20230405171010054.png)\n\n现在需要一键部署自己添加插件编译的 openresty 添加lua脚本以及部署一个基于java的后端服务,并且实现对于java的后端服务实现实时更新的功能，并且通过 Docker Network实现容器之间的相互连接。(如果需要在一键部署中增加redis以及MySQL等等服务也是同理)\n\n## 前置知识\n\n### docker-compose\n\n> Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。\n\n通过docker-compose 可以实现创建多个容器并且控制他们的配置和他们之间的关系，本文将通过docker-compose + shell脚本实现一键化部署。\n\n\n### Docker Network\n\n在Docker中，默认情况下容器与容器、容器与外部宿主机的网络是隔离开来的。安装Docker的时候，docker会创建一个桥接器`docker0`，通过它才让容器与容器之间、与宿主机之间通信。\n\n建议使用自定义的网桥来控制哪些容器可以相互通信，可以通过容器名来实现ip的解析。\n\n在docker-compose.yml中添加以下配置实现创建自定义网桥并且实现容器加入网桥\n\n```yaml\nversion: '3'\nservices:\n  web: \n    ...\n    container_name: oss-application\n    ...\n    networks:\n      - oss-networks\n  openresty: \n  \t....\n    container_name: oss-openresty\n    ....\n    networks:\n      - oss-networks\nnetworks:\n  oss-networks:\n    driver: bridge\n```\n\n\n\n## 编写Openresty的Dockerfile\n\n### 因为要自己重新编译一遍 故base image使用 ubuntu:22.04\n\n```dockerfile\nFROM ubuntu:22.04\n```\n\n### 给docker容器里的apt换源并且安装Openresty运行与编译所需要的相关依赖\n\n```dockerfile\n# 换源\nRUN rm /etc/apt/sources.list && \\\n    touch /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    apt-get clean all\n\n\n# 安装相关依赖\nRUN apt-get update && \\\n    apt-get install -y build-essential libpcre3-dev zlib1g-dev libssl-dev git wget perl curl libxml2 libxml2-dev libxslt-dev\n```\n\n### 编译Openresty 并添加需要的模块\n\n```dockerfile\n# openresty源码并解压\nCOPY ./source/openresty-1.21.4.1.tar.gz /\nRUN cd / && \\\n    tar -xzvf openresty-1.21.4.1.tar.gz && \\\n    cd openresty-1.21.4.1/\n\n# ngx_http_dav_module模块\nCOPY ./source/nginx-dav-ext-module-3.0.0.tar.gz /openresty-1.21.4.1/\nRUN cd /openresty-1.21.4.1 && \\\n    tar -xzvf nginx-dav-ext-module-3.0.0.tar.gz && \\\n    mv nginx-dav-ext-module-3.0.0 nginx-dav-ext-module\n\n\n# 配置并编译openresty\nRUN cd /openresty-1.21.4.1 && \\\n    ./configure --prefix=/usr/local/openresty \\\n    --with-http_dav_module \\\n    --add-module=nginx-dav-ext-module \\\n    --without-http_gzip_module && \\\n    make && \\\n    make install\n```\n\n这里添加的是http_dav_module以及nginx-dav-ext-module模块，可以根据自己的需求定制\n\n### 配置Openresty 相关内容\n\n```dockerfile\n# 拷贝配置文件和lua脚本\nRUN rm -rf /usr/local/openresty/nginx/conf/nginx.conf && \\\n    mkdir -p /usr/local/openresty/nginx/lua && \\\n    mkdir -p /toss/tmp\n\nCOPY ./nginx.conf /usr/local/openresty/nginx/conf/\nCOPY ./lua/referer_and_down_auth.lua /usr/local/openresty/nginx/lua/\nCOPY ./lua/webdav_auth.lua /usr/local/openresty/nginx/lua/\nEXPOSE 80\n```\n\n 这里可以拷贝一些自己要运行的脚本和nginx的配置文件，后面通过路径映射配置也是可以的\n\n### 运行openresty\n\n```dockerfile\n# 运行openresty\nCMD [\"/usr/local/openresty/bin/openresty\", \"-g\", \"daemon off;\"]\n```\n\n### 完成Dockerfile\n\n```dockerfile\nFROM ubuntu:22.04\n\n\n# 换源\nRUN rm /etc/apt/sources.list && \\\n    touch /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-updates main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-backports main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    echo \"deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ jammy-security main restricted universe multiverse\" >> /etc/apt/sources.list && \\\n    apt-get clean all\n\n\n# 安装相关依赖\nRUN apt-get update && \\\n    apt-get install -y build-essential libpcre3-dev zlib1g-dev libssl-dev git wget perl curl libxml2 libxml2-dev libxslt-dev\n\n# openresty源码并解压\nCOPY ./source/openresty-1.21.4.1.tar.gz /\nRUN cd / && \\\n    tar -xzvf openresty-1.21.4.1.tar.gz && \\\n    cd openresty-1.21.4.1/\n\n# ngx_http_dav_module模块\nCOPY ./source/nginx-dav-ext-module-3.0.0.tar.gz /openresty-1.21.4.1/\nRUN cd /openresty-1.21.4.1 && \\\n    tar -xzvf nginx-dav-ext-module-3.0.0.tar.gz && \\\n    mv nginx-dav-ext-module-3.0.0 nginx-dav-ext-module\n\n\n# 配置并编译openresty\nRUN cd /openresty-1.21.4.1 && \\\n    ./configure --prefix=/usr/local/openresty \\\n    --with-http_dav_module \\\n    --add-module=nginx-dav-ext-module \\\n    --without-http_gzip_module && \\\n    make && \\\n    make install\n\n\n# 拷贝配置文件和lua脚本\nRUN rm -rf /usr/local/openresty/nginx/conf/nginx.conf && \\\n    mkdir -p /usr/local/openresty/nginx/lua && \\\n    mkdir -p /toss/tmp\n\n\nCOPY ./nginx.conf /usr/local/openresty/nginx/conf/\nCOPY ./lua/referer_and_down_auth.lua /usr/local/openresty/nginx/lua/\nCOPY ./lua/webdav_auth.lua /usr/local/openresty/nginx/lua/\nEXPOSE 80\n\n# 运行openresty\nCMD [\"/usr/local/openresty/bin/openresty\", \"-g\", \"daemon off;\"]\n\n```\n\n## 编写java应用后端的Dockerfile\n\n这一部分网上很多相似的配置文件没什么好说的\n\n```java\n# java 环境\nFROM openjdk:17-jdk-slim\n# 定义工作目录\nWORKDIR /\n# 把项目中的所有东西复制到工作目录(app)下面 (这里可以改成自己的jar包)\nCOPY ./f-oss-0.0.1-SNAPSHOT.jar /\n# 改变容器的时区\nRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\nRUN echo 'Asia/Shanghai' >/etc/timezone\n#端口号 （这里可以改成自己的运行命令）\nENTRYPOINT [\"java\",\"-jar\",\"/f-oss-0.0.1-SNAPSHOT.jar\",\"--spring.profiles.active=pro\"]\n```\n\n## 通过docker-compose.yml部署\n\n```yml\nversion: '3'\nservices:\n  web: \n    restart: always\n    build: ./application\n    container_name: oss-application\n    dns:\n      - 223.5.5.5\n      - 223.6.6.6\n    volumes:\n      - /toss:/toss:rw\n    networks:\n      - oss-networks\n  openresty: \n    restart: always\n    build: ./openresty\n    # image: openresty-dav:0.1\n    ports:\n      - 12345:80\n    container_name: oss-openresty\n    dns:\n      - 223.5.5.5\n      - 223.6.6.6\n    volumes:\n      - /toss:/toss:rw\n    networks:\n      - oss-networks\nnetworks:\n  oss-networks:\n    driver: bridge\n\n```\n\n目录结构\n\n> │  docker-compose.yml\n> │  install.sh\n> │\n> ├─application\n> │      Dockerfile\n> │      f-oss-0.0.1-SNAPSHOT.jar\n> │\n> └─openresty\n>     │  Dockerfile\n>     │  nginx.conf\n>     │\n>     ├─lua\n>     │      referer_and_down_auth.lua\n>     │      webdav_auth.lua\n>     │\n>     └─source\n>             nginx-dav-ext-module-3.0.0.tar.gz\n>             openresty-1.21.4.1.tar.gz\n\n\n\n在上面的 docker-compose 中将会自动从两个dockerfile中构建docker image，运行，实现目录挂载，端口映射，加入网桥等等操作\n\n通过运行 `docker-compose up`可以看到两个docker container已经被成功拉起\n\n\n\n![image-20230405173539481](https://blog.frzli.top/2023/04/05/docker-compose-shell-%E4%B8%80%E9%94%AE%E5%8C%96%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/image-20230405173539481.png)\n\n![image-20230405173548489](https://blog.frzli.top/2023/04/05/docker-compose-shell-%E4%B8%80%E9%94%AE%E5%8C%96%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E7%9A%84%E4%B8%80%E6%AC%A1%E5%B0%9D%E8%AF%95/image-20230405173548489.png)\n\n\n\n## shell 脚本的引入\n\n通过上面的部署发现当java后端应用更新之后要手动更新重新构建之后的f-oss-0.0.1-SNAPSHOT.jar，从而实现容器中的应用更新。\n\n我们可以通过实现shell脚本实现每次启动时检查更新，并且自动替换f-oss-0.0.1-SNAPSHOT.jar，重新构建镜像\n\n```shell\n#!/bin/bash\n\n# Check if Docker Compose is installed\nif ! [ -x \"$(command -v docker-compose)\" ]; then\n  echo 'Error: docker-compose is not installed.' >&2\n  exit 1\nfi\n\n# Check if wget is installed\nif ! [ -x \"$(command -v wget)\" ]; then\n  echo 'Error: wget is not installed.' >&2\n  exit 1\nfi\n\n\nif 检查更新逻辑 then\n\t下载最新版 f-oss-0.0.1-SNAPSHOT.jar\n\tdocker-compose build (你的service name)\n fi\n\n# 拉起容器\ndocker-compose up -d\n```\n\n\n\n","tags":["运维","docker","docker-compose"]},{"title":"一次线上事故的反思-MySQL中order by与limit一起使用的坑","url":"/2023/03/29/一次线上事故的反思-MySQL中order-by与limit一起使用的坑/","content":"\n\n## 问题场景\n\n一个新项目提供了一个查询所有Bucket的接口，同时使用了Order By 和 limit 同时进行排序和分页查询\n\n```sql\nSELECT\n\t* \nFROM\n\ttb_bucket \nWHERE\n\tuid = ${userId} \nORDER BY\n\tcreate_time DESC \n    limit ${(page - 1)*size}, #{size}\n```\n\n\n\n上线后前端反馈数据出现来回跳动，数据一会出现在第一页一会出现在第二页，导致数据一部分缺失一部分重复\n\n![image-20230329092527083](image-20230329092527083.png)\n\n![image-20230329092538575](image-20230329092538575.png)\n\n## 问题分析\n\n发生问题后首先检查了一遍代码逻辑，并未发现其他问题，当把SQL拿出来单独执行的时候出现了数据错误的问题。发现出现数据错误的数据都有相同的create_time，而SQL又是基于create_time排序的，故怀疑order by 和 limit 同时使用的问题。**以create_time进行降序排序，当create_time存在多条重复时基于limit分页出现数据错误问题。**\n\n\n\n查阅了MySQL的官方文档发现的MySQL limit的查询优化所导致\n\n> If multiple rows have identical values in the `ORDER BY` columns, the server is free to return those rows in any order, and may do so differently depending on the overall execution plan. In other words, the sort order of those rows is nondeterministic with respect to the nonordered columns\n\n大意就是**如果多个行在“ORDER BY”列中具有相同的值，服务器可以自由地以任何顺序返回这些行，并且可能会根据整体执行计划以不同的方式返回。换句话说，这些行的排序顺序相对于未排序的列是不确定的**。\n\n[MySQL 官方文档原文](https://dev.mysql.com/doc/refman/8.0/en/limit-optimization.html)\n\n## 问题解决\n\n解决思路是：避免ORDER BY列的值出现重复。因此，可以加入排序列，比如id等等。\n\n```sql\nSELECT\n\t* \nFROM\n\ttb_bucket \nWHERE\n\tuid = ${userId} \nORDER BY\n\tcreate_time DESC id ASC\n    limit ${(page - 1)*size}, #{size}\n```\n\n加入id作为排序条件后，数据混乱的问题解决\n\n![image-20230329142622876](image-20230329142622876.png)\n\n![image-20230329142652385](image-20230329142652385.png)\n","tags":["后端","MySQL"]},{"title":"Openresty 实现 WebDAV 功能 ，并且实现在 WebDAV 下多用户认证以及访问目录控制","url":"/2023/03/25/Openresty-实现-WebDAV-功能-，并且实现在-WebDAV-下多用户认证以及访问目录控制/","content":"\n\n## 0.介绍\n\n> 基于Web的分布式编写和版本控制（WebDAV）是超文本传输协议（HTTP）的扩展，有利于用户间协同编辑和管理存储在万维网服务器文档。WebDAV由互联网工程任务组的工作组在RFC 4918中定义。\n> WebDAV协议为用户在服务器上创建、更改和移动文档提供了一个框架。WebDAV协议最重要的功能包括维护作者或修改日期的属性、名字空间管理、集合和覆盖保护。维护属性包括创建、删除和查询文件信息等。名字空间管理处理在服务器名称空间内复制和移动网页的能力。集合（Collections）处理各种资源的创建、删除和列举 (from wikipedia)  [wikipedia](https://zh.wikipedia.org/zh-cn/%E5%9F%BA%E4%BA%8EWeb%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%96%E5%86%99%E5%92%8C%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6) \n\nnginx 中的 [ngx_http_dav_module](http://nginx.org/en/docs/http/ngx_http_dav_module.html) 模块提供了该功能的支持，[nginx-dav-ext-module](https://github.com/arut/nginx-dav-ext-module) 主要是实现了 NGINX WebDAV 未实现的命令支持，包括：PROPFIND & OPTIONS 对于完整的 WebDAV 支持\n\n通过 windows 自带的网络驱动器映射可以实现以下效果\n\n![image-20230325204817756](image-20230325204817756.png)\n\n## 1.Openresty 的编译与安装\n\nOpenResty 是一个基于 Nginx 的 Web 平台，整合了诸如 LuaJIT、LuaNginxModule 等模块,所以我们用 Openresty 代替 nginx\n\n因为webdav需要 ngx_http_dav_module 以及 nginx-dav-ext-module 的支持 ，所以我们要自己编译自己的Openresty \n\n**环境 Ubuntu 22.04**\n\n### 1.1 Openresty 源代码下载\n\n通过 [Openresty 官方网站](https://openresty.org/cn/download.html)获取最新的源代码并且解压\n\n```bash\nwget https://openresty.org/download/openresty-1.21.4.1.tar.gz\ntar -xzvf openresty-1.21.4.1.tar.gz\n```\n\n### 1.2 开发依赖安装\n\n```bash\napt-get update\n\napt-get install libpcre3-dev \\\n    libssl-dev perl make build-essential curl \\\n    libxml2 libxml2-dev libxslt-dev\n```\n\n### 1.3 下载 nginx-dav-ext-module 并且配置编译时所添加的module\n\n```bash\ncd openresty-1.21.4.1\n\nwget https://codeload.github.com/arut/nginx-dav-ext-module/tar.gz/refs/tags/v3.0.0 -O nginx-dav-ext-module.tar.gz\n\ntar -xzvf nginx-dav-ext-module.tar.gz\n\n./configure --prefix=/usr/local/openresty \\\n            --with-http_dav_module \\\n            --add-module=nginx-dav-ext-module \\\n            --without-http_gzip_module \n```\n\n### 1.4 编译并且安装 \n\n```bash\ngmake\n\ngmake install \n```\n\n执行上述命令后会发现 Openresty 已经安装在 /usr/local/openresty 但是 openresty 命令还是不可用,可以通过添加软连接实现可以在任意文件夹使用 openresty 命令\n\n```bash\ncd /usr/local/openresty/bin\n\nsudo ln -s `pwd`/openresty /usr/local/bin/openresty\nsudo ln -s `pwd`/opm /usr/local/bin/opm\n```\n\n\n\n运行 Openresty 访问 http://localhost 将会出现 Welcome to OpenResty! 字样，代表 OpenResty 已经安装成功!\n\n\n\n![image-20230325205506326](image-20230325205506326.png)\n\n## 2. 最简单的 Webdav 实现 \n\n修改配置文件 `/usr/local/openresty/nginx/conf/nginx.conf`\n\n```HOCON\nhttp {\n\t... # 你自己的某些配置\n \n    server {\n        ...\n \n        location / {\n        \t# webdav 访问的根目录 ，暂时使用root \n            root /www/wwwroot/webdav; \n    \t\t# 文件暂存地址\n            client_body_temp_path /www/wwwroot/webdav/client_temp; \n \t\t\t# webdav 支持的方法\n            dav_methods PUT DELETE MKCOL COPY MOVE;\n            dav_ext_methods PROPFIND OPTIONS LOCK UNLOCK;\n            \n            create_full_put_path on;\n            dav_access\t\tuser:rw group:rw  all:r;\n \t\t\t# 网页页面自动索引文件\n            autoindex on;\n        }\n    }\n}\n```\n\n这样可以实现最基本的无认证，无动态目录WebDAV \n\n这篇我们编译了带实现 webdav module支持的openresy ，并且实现了最简单的WebDAV，下一篇将会通过编写lua脚本实现多用户认证，以及动态控制访问目录的功能（应该会很快写出来）\n\n\n\n\n\n","tags":["后端","webdav","Openresty","lua"]},{"title":"基础算法-二分答案","url":"/2023/03/21/基础算法-二分答案/","content":"\n## 二分答案： \n\n>解题的时候往往会考虑枚举答案然后检验枚举的值是否正确。若满足单调性，则满足使用二分法的条件。把这里的枚举换成二分，就变成了「二分答案」。[OI-WIKI](https://oi-wiki.org/basic/binary/#%E4%BA%8C%E5%88%86%E7%AD%94%E6%A1%88)\n\n## 二分答案模板\n\n### 寻找 >= 的最小值\n\n```java\n    int bserach_l(int l, int r, int x)\n    {\n        while (l < r) {\n            int mid = l + ((r - l) >> 1); // 防止溢出\n            if (check(mid))\n                r = mid;\n            else\n                l = mid + 1;\n        }\n        return l;\n    }\n```\n\n### 寻找 <= 的模板\n\n```java\n    int bserach_l(int l, int r, int x)\n    {\n        while (l < r) {\n            int mid = l + ((r - l) >> 1) + 1; // 防止溢出\n            if (check(mid))\n                r = mid;\n            else\n                l = mid - 1;\n        }\n        return l;\n    }\n```\n\n### 例题 \n\n例题 [P2440 木材加工](https://www.luogu.com.cn/problem/P2440)\n\n```java\nimport java.util.Scanner;\n\npublic class Main {\n    public static void main(String[] args) {\n        int n,k;\n        Scanner sc = new Scanner(System.in);\n        n = sc.nextInt();\n        k = sc.nextInt();\n        int max = 0;\n        int[] arr = new int[n];\n        for (int i = 0; i < n; i++) {\n            arr[i] = sc.nextInt();\n            max = Math.max(max,arr[i]);\n        }\n        int l = 1 , r = max;\n        int val = 0;\n        int maxVal = 0;\n        int res = 0;\n        while(l <  r){\n            int mid = l + ((r - l) >> 1);\n            val = getChunkNums(arr,mid);\n            if (val < k){\n                r = mid;\n            }else{\n                l = mid + 1;\n                if (mid >= res){\n                    res = mid;\n                    maxVal = val;\n                }\n            }\n\n        }\n        System.out.println(maxVal >= k ? res : 0);\n    }\n\n    public static int getChunkNums(int[] arr,int l){\n        int res = 0;\n        for (int i1 = 0; i1 < arr.length; i1++) {\n            res += arr[i1] / l;\n        }\n        return res;\n    }\n}\n```\n\n","tags":["算法"]},{"title":"go学习笔记和一些语法糖","url":"/2023/03/21/go学习笔记/","content":"\n\n\n### ... 的用法\n\n#### 可变参数\n\n```go\nfunc a(args ...int) int {\n\tfor _, val := range args {\n\t\t// do something\n\t}\n}\n```\n\n#### 打散slice\n\n```go\nfunc a() {\n\ts := []int{1, 2, 3}\n    b(s...)  // 这里的slice {1，2，3} 被打散为 1，2，3 传入函数b\n}\n\nfunc b(args2 ...int) {\n\tfor _, i := range args2 {\n\t\t// do something\n\t}\n}\n```\n\n### go中的继承\n\n先看一段代码\n\n```go\ntype (\n\tRouterGroup struct {\n\t\tprefix      string\n\t\tmiddlewares []HandlerFunc\n\t\tparent      *RouterGroup\n\t\tengine      *Engine\n\t}\n\n\tEngine struct {\n\t\t*RouterGroup\n\t\trouter *router\n\t\tgroups []*RouterGroup\n\t}\n)\n```\n\n可以看到上面`Engine`中包含了`*RouterGroup`这一匿名字段，`Engine` 结构体将直接继承 `RouterGroup` 中的所有字段和方法，并且不需要使用 `.prefix`、`.middlewares`、`.parent` 等字段来引用 `RouterGroup` 中的属性和方法，而可以直接使用 `Engine` 实例进行访问。\n\n### go tag\n\ntag 是一种结构化的注释方式，它可以用于给结构体字段添加元数据，例如字段的名称、类型、格式、验证规则等信息。\n\n示例如下\n\n```go\ntype Person struct {\n    Name string `json:\"name\" xml:\"name\"`\n    Age  int    `json:\"age\" xml:\"age\"`\n}\n```\n\n可以最终通过反射拿到tag的k-v信息\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"reflect\"\n)\n\ntype Person struct {\n    Name string `json:\"name\" xml:\"name\"`\n    Age  int    `json:\"age\" xml:\"age\"`\n}\n\nfunc main() {\n    p := Person{Name: \"Alice\", Age: 25}\n    t := reflect.TypeOf(p)\n    for i := 0; i < t.NumField(); i++ {\n        field := t.Field(i)\n        tag := field.Tag\n        fmt.Printf(\"Field: %s, JSON tag: %s, XML tag: %s\\n\",\n            field.Name, tag.Get(\"json\"), tag.Get(\"xml\"))\n    }\n}\n```\n\n### cap和len\n\n`cap` 和 `len` 都是内置函数，用于获取切片、数组、map 和 channel 的长度和容量信息。\n\nslice作为一个array的引用其cap和len并不一定相等，slice的容量可以动态扩展，如果在使用 `append` 函数将元素添加到切片时长度超过了当前容量，Go 会动态分配一块更大的内存作为底层数组，并将原有数据复制到新的内存空间中，完成切片的扩容过程。如果切片的长度没有超过容量，则不会进行扩容。这个过程会导致切片的地址发生变化。可以通过对比改变前后切片的地址来判断是否扩容。\n\n### any\n\n在go1.18之后添加的新关键字 [all: rewrite `interface{}` to `any` #49884](https://github.com/golang/go/issues/49884)\n\n等同于之前的interface{} \n\n```go\ntype any interface{}\n```\n\n用法\n\n```go\nfunc a(v any) {\n\tswitch v.(type) {\n\tcase int:\n\t\tfmt.Println(\"int type val\")\n\tcase bool:\n\t\tfmt.Println(\"bool type val\")\n\t}\n}\n```\n\n","tags":["后端","go"]},{"title":"SpringBoot创建自己的Start","url":"/2023/03/05/SpringBoot创建自己的Starter/","content":"\n1. 创建SpringBoot项目\n\n   包含以下依赖\n\n```xml\n \t\t<dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter</artifactId>\n        </dependency>\n\n\t     <!--自动生成meta-data-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-configuration-processor</artifactId>\n            <optional>true</optional>\n        </dependency>\n            \n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n```\n\n2. 修改`pom.xml`\n\n   修改pom.xml为对应项目名称 \n\n   starter推荐命名 xxxxx-start\n\n   ```xml\n       <groupId>com.frz</groupId>\n       <artifactId>frzApi-client-sdk</artifactId>\n       <version>0.0.2</version>\n       <name>frzApi-client-sdk</name>\n       <description>frzApi-client-sdk</description>\n   ```\n\n3. 编写`AutoConfiguration`\n\n   ```java\n   @Configuration\n   @ConfigurationProperties(\"frzapi.client\")\n   @Data\n   @ComponentScan\n   public class FrzApiClientConfig {\n       private String accessKey;\n       private String secretKey;\n       @Bean\n       public FrzApiClient frzApiClient(){\n           return new FrzApiClient(accessKey, secretKey);\n       }\n   }\n   ```\n\n   通过`ConfigurationProperties`注解能够读取application 中的配置属性\n\n4. 配置`EnableAutoConfiguration`\n\n   在`resource/META-INF`创建`spring.factories`文件,设置\n\n   ```properties\n   org.springframework.boot.autoconfigure.EnableAutoConfiguration=xxx\n   ```\n\n   > xxx为配置类Reference\n\n![目录结构](im1.png \"目录结构\")\n\n通过maven install 后即成功安装到本地maven仓库\n\n在其他项目的依赖中添加\n\n```xml\n<dependency>\n   <groupId>com.frz</groupId>\n   <artifactId>frzApi-client-sdk</artifactId>\n   <version>0.0.2</version>\n</dependency>\n```\n\n既可以正常使用\n\n\n\n","tags":["后端","sprigboot","java"]}]